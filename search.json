[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Movement Analysis: Patterns and Trends in Environmental Data",
    "section": "",
    "text": "Welcome to the course!\nFor the practical part of the course, building-up skills for analysing movement data in the software environment R, you’ll be using data from the ZHAW project “Prävention von Wildschweinschäden in der Landwirtschaft”.\nThe project investigates the spatiotemporal movement patterns of wild boar (Sus scrofa) in agricultural landscapes. We will study the trajectories of these wild boar, practising the most basic analysis tasks of Computational Movement Analysis (CMA).",
    "crumbs": [
      "Welcome to the course!"
    ]
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Computational Movement Analysis: Patterns and Trends in Environmental Data",
    "section": "License",
    "text": "License\nThese R Exercises are created by Patrick Laube, Nils Ratnaweera, Nikolaos Bakogiannis and Dominic Lüönd for the Course Computational Movement Analysis and are licensed under Creative Commons Attribution 4.0 International License.\nThis work is licensed under a Creative Commons Attribution 4.0 International License.",
    "crumbs": [
      "Welcome to the course!"
    ]
  },
  {
    "objectID": "Intro/W0_1_preparations_course.html",
    "href": "Intro/W0_1_preparations_course.html",
    "title": "Preparation Course",
    "section": "",
    "text": "Install or update R\nIf you haven’t installed R yet, do so now by getting the newest version from CRAN. If you do have R installed, check your Version of R by opening RStudio and typing the following command into the console.\nR.version.string\n\n[1] \"R version 4.2.1 (2022-06-23)\"\nThis returns the version number of your R installation, whereas the first digit (4) indicates the number of the major release, the second digit (2) indicates the minor release and the last digit (1) refers to the patch release. As a general rule of thumb, you will want to update R if you\nIn the time of writing (April, 2023), the current R Version is 4.2.3 (released on 15.03.2023, see cran.r-project.org). Your installation should therefore not be older than 4.1.0. If it is, make sure that you have updated R before the course. Check these instructions on how to update R",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "Intro/W0_1_preparations_course.html#install-or-update-r",
    "href": "Intro/W0_1_preparations_course.html#install-or-update-r",
    "title": "Preparation Course",
    "section": "",
    "text": "don’t have the current major version or\nare lagging two (or more) versions behind the current minor release",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "Intro/W0_1_preparations_course.html#install-or-update-rstudio",
    "href": "Intro/W0_1_preparations_course.html#install-or-update-rstudio",
    "title": "Preparation Course",
    "section": "Install or update RStudio",
    "text": "Install or update RStudio\nRStudio is the IDE (integrated development environment) we use in our course to interact with R. There are good alternatives you can use, RStudio simply seems to be the most popular choice. If you want to use your own IDE, please feel free to do so. However, we don’t recommend this if you are a beginner.\nWe recommend updating RStudio to the newest version before the course: check if this is the case by clicking on help &gt; check for updates.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "Intro/W0_1_preparations_course.html#install-the-necessary-packages",
    "href": "Intro/W0_1_preparations_course.html#install-the-necessary-packages",
    "title": "Preparation Course",
    "section": "Install the necessary packages",
    "text": "Install the necessary packages\nIn the course, we will be needing the following packages (amongst others). Save time during the course by installing these upfront! Check if you can load the packages by calling library(\"dplyr\").\n\ninstall.packages(\"dplyr\")\ninstall.packages(\"ggplot2\")\ninstall.packages(\"readr\")\ninstall.packages(\"tidyr\")\ninstall.packages(\"sf\")\ninstall.packages(\"terra\")\ninstall.packages(\"quarto\")",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "Intro/W0_1_preparations_course.html#install-git",
    "href": "Intro/W0_1_preparations_course.html#install-git",
    "title": "Preparation Course",
    "section": "Install Git",
    "text": "Install Git\nGit is a software dedicated to tracking changes in text files (e.g. R scripts). It’s heavily used in the software industry as well as in the field of data science. In this course, we will teach use the basic functionalities of Git and combine it with the online portal Github.\nTherefore, the next step is to install Git. There are different Git installers to choose from, we recommend the following:\n\nWindows:\n\nWe recommend installing Git for Windows, also known as msysgit or “Git Bash”.\nWhen asked about “Adjusting your PATH environment”, select “Git from the command line and also from 3rd-party software”\nRStudio prefers Git to be installed in C:/Program Files/Git, we recommend following this convention\nOtherwise, we believe it is good to accept the defaults\n\nmacOS:\n\nWe recommend you install the Xcode command line tools (not all of Xcode), which includes Git\nGo to the shell and enter xcode-select --install to install developer command line tools\n\nLinux:\n\nOn Ubuntu or Debian Linux: sudo apt-get install git\nOn Fedora or RedHat Linux: sudo yum install git\n\n\n\nMuch of this chapter was taken from Bryan and Heister (2021). If you want to dive deeper into using Git, we highly recommend this book. For an even deeper dive into Git, read Chacon and Straub (2014). Both books are available free and open source on happygitwithr.com and git-scm.com/book, respectively.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "Intro/W0_1_preparations_course.html#configure-rstudio",
    "href": "Intro/W0_1_preparations_course.html#configure-rstudio",
    "title": "Preparation Course",
    "section": "Configure RStudio",
    "text": "Configure RStudio\nNow we will set some RStudio Global options. But first, close all instances of RStudio and restart it (!!!). Then go to Tools &gt; Global options.\n\nR General\n\nDeactivate the option “Restore .RData into workspace at startup”1\nSet “Save workspace to .RData on exit” to “Never”2\n\nCode\n\nActivate the option “Use native pipe operator, |&gt; (requires R 4.1+)”\n\nR Markdown\n\nDeactivate the option “Show output inline for all R Markdown documents”\n\nGit / SVN\n\nActivate the option “Enable version control interface for RStudio projects”\nIf the Field “Git executable:” shows (Not Found), browse to your git installation (previous step). This path should look something like this:\n\nWindows: C:/Program Files/Git/bin/git.exe (not C:/Program Files/Git/cmd/git.exe or some-path/git-bash.exe)\nLinux / macOS: /usr/bin/git\n\n\nTerminal\n\nSet option “New terminals open with” to “Git Bash”\n\n\nClick on “Ok” to apply the change and close the options menu.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "Intro/W0_1_preparations_course.html#introduce-yourself-git",
    "href": "Intro/W0_1_preparations_course.html#introduce-yourself-git",
    "title": "Preparation Course",
    "section": "Introduce yourself to Git",
    "text": "Introduce yourself to Git\nNow it is time to introduce yourself to git. For this, we need to use the shell terminal, which is why we are going to spend a few word on the shell first.\nThe shell is a program on your computer whose job is to run other programs. It looks very much like the R-console (in the bottom left of RStudio) that you are already know: You have a place to input text which is transferred to (and interpreted by) the computer when you press “enter”. RStudio has a shell terminal right next to the R-console (tab Terminal).\nEvery Windows comes with two different shell installations: “Command prompt” and “PowerShell”. After installing Git we now have a third option, “Git Bash”. The shell terminal in RStudio uses “Command prompt” per default, in the last step we just switched the shell to “Git Bash”.\nNow use the terminal in RStudio to introduce yourself:\n  git config --global user.name \"Maria Nusslinger\"\n  git config --global user.email \"nussmar@email.com\"\nOf course, replace the name and address with your credentials. Use the email address that you will use to create your Github account (which we will do next week).\n\n\n\n\n\n\nNote to users who already have a Github account\n\n\n\nIf you already have a Github account and don’t want to associate the work you do in this course with said account, we recommend the following approach:\n\nCreate a new Github account with a different mailaddress (e.g. your student mail address)\nOverride your user.name and user.email on a per project basis (by omitting the --global flag)\n\nPlease feel free to contact us if you have questions about this.\n\n\n\n\n\n\nBryan, Jenny, and Jim Heister. 2021. Happy Git and GitHub for the useR. https://happygitwithr.com/.\n\n\nChacon, Scott, and Ben Straub. 2014. Pro Git. 2nd Edition. Apress. https://git-scm.com/book/en/v2.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. 1st ed. O’Reilly Media, Inc.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "Intro/W0_1_preparations_course.html#footnotes",
    "href": "Intro/W0_1_preparations_course.html#footnotes",
    "title": "Preparation Course",
    "section": "",
    "text": "We recommend that you start each RStudio session with a blank slate, as recommended by Wickham and Grolemund (2017) see here↩︎\nIf we don’t restore the workspace at startup, there is no need to save it on exit.↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Preparation Course</span>"
    ]
  },
  {
    "objectID": "Intro/W0_2_preparations_project.html",
    "href": "Intro/W0_2_preparations_project.html",
    "title": "Preparation Project",
    "section": "",
    "text": "Option 1: Tracking App Posmo\nYou use the tracking app Posmo, and as a side effect become part of an experiment we currently conduct in one of our research projects.\nThe Posmo app will continuously track your daily movements and will automatically determine your kind of transportation. You will then filter for the relevant cycling data. Find more information on how the app works in their FAQ.\nIn order to join our research project just follow the instructions on the following flyer.\nIf you have any issues during installation or you are not able to track yourself after the installtion please get in contact with Nils or Dominic.\nIf, however, for privacy reasons, you prefer not to contribute to our study, we can hand out a GPS tracker to you.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preparation Project</span>"
    ]
  },
  {
    "objectID": "Intro/W0_2_preparations_project.html#option-1-tracking-app-posmo",
    "href": "Intro/W0_2_preparations_project.html#option-1-tracking-app-posmo",
    "title": "Preparation Project",
    "section": "",
    "text": "Figure 2.1: Flyer Project Bikeability",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preparation Project</span>"
    ]
  },
  {
    "objectID": "Intro/W0_2_preparations_project.html#option-2-gps-tracker",
    "href": "Intro/W0_2_preparations_project.html#option-2-gps-tracker",
    "title": "Preparation Project",
    "section": "Option 2: GPS Tracker",
    "text": "Option 2: GPS Tracker\nYou can use a GPS tracker, provided by our research group. By using a GPS tracker all your data will stay with you locally.\nYou can get the tracker in our office GC 134 at the Campus Grüental, Wädenswil.\nPlease send us a quick E-Mail so we can arrange the handover of the GPS tracker.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Preparation Project</span>"
    ]
  },
  {
    "objectID": "Week1/W1_4_preparation.html",
    "href": "Week1/W1_4_preparation.html",
    "title": "Preparation",
    "section": "",
    "text": "Folder structure for this course\nBy this point, you probably have created a folder for this course somewhere on your computer. In our example, we assume this folder is located here: C:/Users/yourname/semester2/Modul_CMA (mentally replace this with your actual path). Before we dive into the exercises, take a minute to think about how you are going to structure your files in this folder. This course will take place over 6 weeks, and in each week you will receive or produce various files. We recommend creating a separate folder for each week, and one folder for the semester project, like so:\nFor the R-exercises that take place in weeks 1 to 5, we recommend that you create a new RStudio Project each week in subdirectory of the appropriate week. For example, this week your folder structure could look like this:\nNote:",
    "crumbs": [
      "Exercise 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preparation</span>"
    ]
  },
  {
    "objectID": "Week1/W1_4_preparation.html#footnotes",
    "href": "Week1/W1_4_preparation.html#footnotes",
    "title": "Preparation",
    "section": "",
    "text": "You will see the project names of all your RStudio Projects listed in RStudio. Having the week number in the project name keeps you from getting confused on which project you are working on.↩︎",
    "crumbs": [
      "Exercise 1",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Preparation</span>"
    ]
  },
  {
    "objectID": "Week1/W1_5_tasks_and_inputs.html",
    "href": "Week1/W1_5_tasks_and_inputs.html",
    "title": "Tasks and inputs",
    "section": "",
    "text": "Once you have set everything up, commit your file to your git repo in the following manner:",
    "crumbs": [
      "Exercise 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tasks and inputs</span>"
    ]
  },
  {
    "objectID": "Week1/W1_5_tasks_and_inputs.html#footnotes",
    "href": "Week1/W1_5_tasks_and_inputs.html#footnotes",
    "title": "Tasks and inputs",
    "section": "",
    "text": "Our reasons for preferring readr over base-R import functions:\n\nbase R imports strings as factors by default (since R 4.0.0, this is not the case anymore)\nreadr is generally faster (which only matters if you have a large dataset)\nreadr makes safer assumptins about your data (e.g. the default timezone for datetime columns is UTC)\ndata.frames created by readr are prettier when printed to the console and contain more information using less characters\n\nHOWEVER: Using external libraries (such as readr) creates additional dependencies which has it’s own downsides (which is one of the reasons we don’t do library(\"tidyverse\")).↩︎\nAs we’ve mentioned in the first Input, you can look up the EPSG codes under epsg.io. For information specific to Switzerland, check the swisstopo website↩︎",
    "crumbs": [
      "Exercise 1",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Tasks and inputs</span>"
    ]
  },
  {
    "objectID": "Week1/W1_6_solutions.html",
    "href": "Week1/W1_6_solutions.html",
    "title": "Solutions",
    "section": "",
    "text": "Tip\n\n\n\nHover over the code and copy the content by clicking on the clipboard icon on the top right. You can now paste this into an R-Script.\n\n\n\n\n# task_1.R\n################################################################################\n\n\n\nlibrary(\"readr\")\n\n# Data import ####\nwildschwein_BE &lt;- read_delim(\"datasets/wildschwein_BE.csv\", \",\")\n\n# Check Timezone\nattr(wildschwein_BE$DatetimeUTC, \"tzone\") # or\nwildschwein_BE$DatetimeUTC[1]\n\n\n\n\n# task_2.R\n################################################################################\n\n\nlibrary(\"ggplot2\")\n\nggplot(wildschwein_BE, aes(Long, Lat, colour = TierID)) +\n  geom_point() +\n  theme(legend.position = \"none\")\n\n\n\n\n# task_3.R\n################################################################################\n\n\n\nlibrary(\"sf\")\n\nwildschwein_BE &lt;- st_transform(wildschwein_BE, 2056)\n\n\n\n\n# task_4.R\n################################################################################\n\n\n\nggplot(mcp, aes(fill = TierID)) +\n  geom_sf(alpha = 0.4)\n\nggplot(mcp, aes(fill = TierID)) +\n  geom_sf(alpha = 0.4) +\n  coord_sf(datum = 2056)\n\n\n\n\n# task_5.R\n################################################################################\n\n\n\nlibrary(\"tmap\")\n\ntm_shape(pk100_BE) +\n  tm_rgb() +\n  tm_shape(mcp) +\n  tm_polygons(col = \"TierID\", alpha = 0.4, border.col = \"red\") +\n  tm_legend(bg.color = \"white\")\n\n\n\n\n# task_6.R\n################################################################################\n\n\ntmap_mode(\"view\")\n\ntm_shape(mcp) +\n  tm_polygons(col = \"TierID\", alpha = 0.4, border.col = \"red\") +\n  tm_legend(bg.color = \"white\")",
    "crumbs": [
      "Exercise 1",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Solutions</span>"
    ]
  },
  {
    "objectID": "Week2/W2_3_preparation.html",
    "href": "Week2/W2_3_preparation.html",
    "title": "Preparation",
    "section": "",
    "text": "This week, we are going to further leverage Git by connecting it to an online repository. Git on it’s own can be useful, but to use all of the advantages its best to combine it with an hosted service like Github.\n\nStep 1: Create a Github account\nTypically, you do this once (in a lifetime)\nLast week, you worked with git on your local machine, with no way of synchronising your changes with a cloud server. This week you will use Github to sync your changes. To do this, create a Github account on github.com (it’s free of course). Use the email address that you configured in git last week. If you are not sure which mail you used, type git config user.email in the shell terminal.\nYou don’t have to use the same username on Github and in Git. When choosing a username on Github, consider the following advice:\n\nincorporating your actual name is nice, people like to know who they are dealing with\nchoose a name that you are comfortable revealing it to a future boss\nshorter is better than longer\nmake it timeless (e.g. don’t incorporate your university’s name)\n\n\n\nStep 2: Authenticate Git to work with Github\nTypically, you do this once (per computer)\nIf we want to push changes from our local repository to your Github cloud repository, Github must verify your credentials. Other software might just ask for your username and password, it’s a little different with Git. Basically there are two ways to connect with your remote repo (ssh and https), we will use https in this course.\nFirst, create a personal access token (PAT) on Github\n\nLogin into github.com, click on your user profile (top right) and click on “Settings”\nChoose Developer settings &gt; Personal access tokens &gt; Generate new token\nAdd a descriptive note (e.g. https access from my personal laptop)\nSelect scope “repo”\nClick on “Generate token”\nCopy your new personal access token (in the green box)\n\nYou won’t be able to see this token again\nIf you loose it, you can simply create a new one\nIf you want to store it, you neeed to treat this Personal access tokens (PAT) like a password. Only store it in a secure place (like a password management app) and never publish this PAT publicly\n\n\nThen, store your PAT in you local Git\n\nIn R, install the gitcreds package (install.packages(\"gitcreds\"))\nLoad this library (library(\"gitcreds\"))\nCall the function gitcreds_set()\nRespond to the prompt with your PAT from the last step\nCheck that you have stored a credential with gitcreds_get()\n\n\n\nStep 3: Create a Github repo\nTypically, you do this once per project\nNow you can create a repository on Github that you can afterwards connect to your RStudio project from this week (which you will create in the next step). To do this, go to github.com and click on the plus sign in the top right corner, then fill in the following information:\n\nRepository name: Give a meaningful name, e.g. cma-week2\nDescription: Give a meaningful description, e.g. Solving exercise 2 of the course \"Computational Movement Analysis\"\nMake the repo public, not private\nChoose Add a README file\n\nClick on Create repository, then on the green button “Code”. Select HTTPS (it might already be selected) and then copy the URL by clicking on the clipboard symbol. The URL should look something list this https://github.com/YOUR-GITHUB-USERNAME/cma-week2.git.\n\n\n\n\n\n\nImportant\n\n\n\nReport this URL back to us via Moodle (under L2 Data Issues &gt; R Exercises E2 &gt; Exercise 2 (Github URL))\n\n\n\n\nStep 4: Create a new RStudio Project\nTypically, you do this once per project\nYou will now create a new RStudio Project for week 2. Unlike last week, we will create the project in such a way that it is immediately connected to our Github repo. In RStudio, start a new project. Choose: File &gt; New Project &gt; Version Control &gt; Git.\n\nIn the repository URL, paste the URL you copied in the last step\nChange “Project directory name” to cma-week2-rexercise (if you are following the convention we proposed last week)\nChange the parent directory (Create project as a subdirectory of) to your equivalent of C:/Users/yourname/semester2/Modul_CMA/week2\n\nClick on “Create Project”. You are now all set and can start with this week’s tasks!\nPS: You just created an RStudio Project which is automatically connected to Github. You can also connect existing local Git repositories (e.g. from week 1) to Github. You have the chance to learn this in Week 3.",
    "crumbs": [
      "Exercise 2",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Preparation</span>"
    ]
  },
  {
    "objectID": "Week2/W2_4_demo_tidyverse.html",
    "href": "Week2/W2_4_demo_tidyverse.html",
    "title": "Toolskit Demo",
    "section": "",
    "text": "Download this Demoscript via “&lt;/&gt;Code” (top right)\nDepending on your knowledge of R, getting an overview of the data we imported last week might have been quite a challenge. Surprisingly enough, importing, cleaning and exploring your data can be the most challenging, time consuming part of a project. RStudio and the tidyverse offer many helpful tools to make this part easier (and more fun). You have read chapters on dplyr and magrittr as a preparation for this exercise. Before we start with the exercise however, this demo illustrates a simple approach offered by tidyverse which is applicable to sf-objects.\nAssume we want to calculate the timelag between subsequent positions. To achieve this we can use the function difftime() combined with lead() from dplyr. Let’s look at these functions one by one.\n\ndifftime\ndifftime takes two POSIXct values.\n\nnow &lt;- Sys.time()\n\nlater &lt;- now + 10000\n\nlater\n\n[1] \"2023-05-11 12:39:54 CEST\"\n\ntime_difference &lt;- difftime(later, now)\n\ntime_difference\n\nTime difference of 2.777778 hours\n\n\nYou can also specify the unit of the output.\n\ntime_difference &lt;- difftime(later, now, units = \"mins\")\n\ntime_difference\n\nTime difference of 166.6667 mins\n\n\ndifftime returns an object of the Class difftime. However in our case, numeric values would be more handy than the Class difftime. So we’ll wrap the command in as.numeric():\n\nclass(time_difference)\n\n[1] \"difftime\"\n\nstr(time_difference)\n\n 'difftime' num 166.666666666667\n - attr(*, \"units\")= chr \"mins\"\n\n\n\ntime_difference &lt;- as.numeric(difftime(later, now, units = \"mins\"))\n\nstr(time_difference)\n\n num 167\n\nclass(time_difference)\n\n[1] \"numeric\"\n\n\n\n\nlead() / lag()\nlead() and lag() return a vector of the same length as the input, just offset by a specific number of values (default is 1). Consider the following sequence:\n\nnumbers &lt;- 1:10\n\nnumbers\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nWe can now run lead() and lag() on this sequence to illustrate the output. n = specifies the offset, default = specifies the default value used to “fill” the emerging “empty spaces” of the vector. This helps us performing operations on subsequent values in a vector (or rows in a table).\n\nlibrary(\"dplyr\")\n\nlead(numbers)\n\n [1]  2  3  4  5  6  7  8  9 10 NA\n\nlead(numbers, n = 2)\n\n [1]  3  4  5  6  7  8  9 10 NA NA\n\nlag(numbers)\n\n [1] NA  1  2  3  4  5  6  7  8  9\n\nlag(numbers, n = 5)\n\n [1] NA NA NA NA NA  1  2  3  4  5\n\nlag(numbers, n = 5, default = 0)\n\n [1] 0 0 0 0 0 1 2 3 4 5\n\n\n\n\nmutate()\nUsing the above functions (difftime() and lead()), we can calculate the time lag, that is, the time difference between consecutive positions. We will try this on a dummy version of our wildboar dataset.\n\nwildschwein &lt;- tibble(\n    TierID = c(rep(\"Hans\", 5), rep(\"Klara\", 5)),\n    DatetimeUTC = rep(as.POSIXct(\"2015-01-01 00:00:00\", tz = \"UTC\") + 0:4 * 15 * 60, 2)\n)\n\nwildschwein\n\n# A tibble: 10 × 2\n   TierID DatetimeUTC        \n   &lt;chr&gt;  &lt;dttm&gt;             \n 1 Hans   2015-01-01 00:00:00\n 2 Hans   2015-01-01 00:15:00\n 3 Hans   2015-01-01 00:30:00\n 4 Hans   2015-01-01 00:45:00\n 5 Hans   2015-01-01 01:00:00\n 6 Klara  2015-01-01 00:00:00\n 7 Klara  2015-01-01 00:15:00\n 8 Klara  2015-01-01 00:30:00\n 9 Klara  2015-01-01 00:45:00\n10 Klara  2015-01-01 01:00:00\n\n\nTo calculate the timelag with base-R, we need to mention wildschwein three times\n\nwildschwein$timelag &lt;- as.numeric(difftime(lead(wildschwein$DatetimeUTC), wildschwein$DatetimeUTC))\n\nUsing mutate() we can simplify this operation slightly:\n\nwildschwein &lt;- mutate(wildschwein, timelag = as.numeric(difftime(lead(DatetimeUTC), DatetimeUTC)))\n\nwildschwein\n\n# A tibble: 10 × 3\n   TierID DatetimeUTC         timelag\n   &lt;chr&gt;  &lt;dttm&gt;                &lt;dbl&gt;\n 1 Hans   2015-01-01 00:00:00      15\n 2 Hans   2015-01-01 00:15:00      15\n 3 Hans   2015-01-01 00:30:00      15\n 4 Hans   2015-01-01 00:45:00      15\n 5 Hans   2015-01-01 01:00:00     -60\n 6 Klara  2015-01-01 00:00:00      15\n 7 Klara  2015-01-01 00:15:00      15\n 8 Klara  2015-01-01 00:30:00      15\n 9 Klara  2015-01-01 00:45:00      15\n10 Klara  2015-01-01 01:00:00      NA\n\n\n\n\ngroup_by()\nYou might have noticed that timelag is calculated across different individuals (Hans and Klara), which does not make much sense. To avoid this, we need to specify that timelag should just be calculated between consecutive rows of the same individual. We can implement this by using group_by().\n\nwildschwein &lt;- group_by(wildschwein, TierID)\n\nAfter adding this grouping variable, calculating the timelag automatically accounts for the individual trajectories.\n\nwildschwein &lt;- mutate(wildschwein, timelag = as.numeric(difftime(lead(DatetimeUTC), DatetimeUTC)))\n\nwildschwein\n\n# A tibble: 10 × 3\n# Groups:   TierID [2]\n   TierID DatetimeUTC         timelag\n   &lt;chr&gt;  &lt;dttm&gt;                &lt;dbl&gt;\n 1 Hans   2015-01-01 00:00:00      15\n 2 Hans   2015-01-01 00:15:00      15\n 3 Hans   2015-01-01 00:30:00      15\n 4 Hans   2015-01-01 00:45:00      15\n 5 Hans   2015-01-01 01:00:00      NA\n 6 Klara  2015-01-01 00:00:00      15\n 7 Klara  2015-01-01 00:15:00      15\n 8 Klara  2015-01-01 00:30:00      15\n 9 Klara  2015-01-01 00:45:00      15\n10 Klara  2015-01-01 01:00:00      NA\n\n\n\n\nsummarise()\nIf we want to summarise our data and get metrics per animal, we can use the dplyr function summarise(). In contrast to mutate(), which just adds a new column to the dataset, summarise() “collapses” the data to one row per individual (specified by group_by).\n\nsummarise(wildschwein, mean = mean(timelag, na.rm = T))\n\n# A tibble: 2 × 2\n  TierID  mean\n  &lt;chr&gt;  &lt;dbl&gt;\n1 Hans      15\n2 Klara     15\n\n\nNote: You can do mutate() and summarise() on sf objects as well. However, summarise() tries to coerce all geometries into one object, which can take along time. To avoid this, use st_drop_geometry() before using summarise().\n\n\nPiping\nThe code above may be a bit hard to read, since it has so many nested functions which need to be read from the inside out. In order to make code readable in a more human-friendly way, we can use the piping command |&gt; from magrittr, which is included in dplyr and the tidyverse. The above code then looks like this:\n\nwildschwein |&gt; # Take wildschwein...\n    group_by(TierID) |&gt; # ...group it by TierID\n    summarise( # Summarise the data...\n        mean_timelag = mean(timelag, na.rm = T) # ...by calculating the mean timelag\n    )\n\n# A tibble: 2 × 2\n  TierID mean_timelag\n  &lt;chr&gt;         &lt;dbl&gt;\n1 Hans             15\n2 Klara            15\n\n\n\n\nBring it all together…\nHere is the same approach with a different dataset:\n\npigs &lt;- tibble(\n    TierID = c(8001, 8003, 8004, 8005, 8800, 8820, 3000, 3001, 3002, 3003, 8330, 7222),\n    sex = c(\"M\", \"M\", \"M\", \"F\", \"M\", \"M\", \"F\", \"F\", \"M\", \"F\", \"M\", \"F\"),\n    age = c(\"A\", \"A\", \"J\", \"A\", \"J\", \"J\", \"J\", \"A\", \"J\", \"J\", \"A\", \"A\"),\n    weight = c(50.755, 43.409, 12.000, 16.787, 20.987, 25.765, 22.0122, 21.343, 12.532, 54.32, 11.027, 88.08)\n)\n\npigs\n\n# A tibble: 12 × 4\n   TierID sex   age   weight\n    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;\n 1   8001 M     A       50.8\n 2   8003 M     A       43.4\n 3   8004 M     J       12  \n 4   8005 F     A       16.8\n 5   8800 M     J       21.0\n 6   8820 M     J       25.8\n 7   3000 F     J       22.0\n 8   3001 F     A       21.3\n 9   3002 M     J       12.5\n10   3003 F     J       54.3\n11   8330 M     A       11.0\n12   7222 F     A       88.1\n\npigs |&gt;\n    summarise(\n        mean_weight = mean(weight)\n    )\n\n# A tibble: 1 × 1\n  mean_weight\n        &lt;dbl&gt;\n1        31.6\n\npigs |&gt;\n    group_by(sex) |&gt;\n    summarise(\n        mean_weight = mean(weight)\n    )\n\n# A tibble: 2 × 2\n  sex   mean_weight\n  &lt;chr&gt;       &lt;dbl&gt;\n1 F            40.5\n2 M            25.2\n\npigs |&gt;\n    group_by(sex, age) |&gt;\n    summarise(\n        mean_weight = mean(weight)\n    )\n\n# A tibble: 4 × 3\n# Groups:   sex [2]\n  sex   age   mean_weight\n  &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n1 F     A            42.1\n2 F     J            38.2\n3 M     A            35.1\n4 M     J            17.8",
    "crumbs": [
      "Exercise 2",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Toolskit Demo</span>"
    ]
  },
  {
    "objectID": "Week2/W2_5_tasks_and_inputs.html",
    "href": "Week2/W2_5_tasks_and_inputs.html",
    "title": "Tasks and Inputs",
    "section": "",
    "text": "Open the RStudio Project you created in preparation to this exercise\nDownload the new wildboar movement data, and save it to your new project’s directory wildschwein_BE_2056.csv\n\n\nOnce you have set everything up, commit your file to your git repo in the following manner:\n\n\n\n\n\n\nCommitting files with git\n\n\n\n\nSave your (R/RMarkdown/Quarto) file\nSwitch to the “Git”-Tab in the pane in the top right corner\nClick “commit” to open the “Commit Window”\nClick in the checkbox next to the file(s) you want to commit\nAdd a commit message to explain what you are committing (e.g. “initial commit”)\nClick on “commit” to commit your changes\n\n\n\nTo push your changes from our local repo on your computer to the remote repo on Github, simply click the green button “Push” in the Git tab in RStudio. Now take a look at your repository on github.com. Do you see the new files there? Contact us if this does not work.\nNote: You do not need to push your changes to your remote repo after every commit. It’s enough if you do this every few commits.\n\n\nTask 1: Import your data\nCreate a new R- (or RMarkdown/Quarto-) file and begin with the following lines of code (adjust the path to your csv file accordingly).\n\nlibrary(\"readr\") \nlibrary(\"sf\") \n\nwildschwein_BE &lt;- read_delim(\"datasets/wildschwein_BE_2056.csv\", \",\")\n\nwildschwein_BE &lt;- st_as_sf(wildschwein_BE, coords = c(\"E\", \"N\"), crs = 2056, remove = FALSE)\n\nNote:\n\nthat this dataset is already converted to EPSG 2056\nthe coordinates are stored in the columns (E/N)\nsetting remove = FALSE preserves the original (E/N) columns, which come in handy later on\n\n\n\nTask 2: Getting an overview\nCalculate the time difference between subsequent rows as described in the demo. You can calculate the time difference using the function difftime() in combination with lead().\n\nthe function difftime() has an option units. Set this to secs to get the time difference in seconds\nuse as.integer() to turn the output returned by difftime() into an integer.\nstore the output in a new column (e.g. timelag)\n\nNow inspect your data in more detail. Try to answer the following questions:\n\nHow many individuals were tracked?\nFor how long were the individual tracked? Are there gaps?\nWere all individuals tracked concurrently or sequentially?\nWhat is the temporal sampling interval between the locations?\n\nAfter completing the task, commit your changes to git using a good commit message (e.g. completed task 1).\n\n\n\nTask 3: Deriving movement parameters I: Speed\nIn this task we will derive some additional movement parameters from our trajectories. So far our trajectories only consist of a list of time-stamped spatial locations. So let’s calculate the animal’s steplength based on the Euclidean distance between subsequent locations.\n\n\n\n\n\n\nNote\n\n\n\nSince our wildboar data is an sf object, we could use the function st_distance to calulate the distance between locations. However, st_distance is not designed for movement data, and using it with our split-apply-combine paradigm turns out to be a bit complicated (checkout the answers to my Stackoverflow question posted in 2018).\nLuckily, we are working with cartesian coordinates and so can create our own distance function more suited to our use case. If one day you work with geodetic coordinates and need to do something similar, please use one of the solutions provided in the linked stackoverflow questions instead!\n\n\nYou can calculate the Euclidean distance with the following formula: \\[\\text{distance} = \\sqrt{(\\text{E1} - \\text{E2})^{2}+(\\text{N1} - \\text{N2})^{2}}\\]\n\nE1, N1 refers to the current location\nE2, N2 refers to the consecutive location\nyou can use lead(E,1) to address E2\nstore the output in a new column (e.g. steplength)\n\nNow calculate the animals’ speed between consecutive locations based on steplength and the timelag (from the last task). What speed unit do you get?\nAfter completing the task, commit your changes to git using a good commit message.\n\n\nTask 4: Cross-scale movement analysis\nLaube and Purves (2011) analyse animal movement across different scales (see below). In their paper, the authors suggest reducing the granularity of the data by subsetting the data to every nth element. We will do the same on a dataset that includes 200 locations of a single wild boar with a constant sampling interval of 60 seconds.\n\n\n\nBlack points are used in calculation of movement parameters (e.g. speed) at a given termporal scale (Laube and Purves, 2011)\n\n\nDownload this dataset here: caro60.csv. Import it just like you imported the other wild boar data and save it to a new variable named caro (note that the locations are stored in EPSG 2056).\nNow manually reduce the granularity of our sampling interval by selecting every 3rd, 6th and 9th position and save the output to caro_3, caro_6,caro_9 accordingly.\nTip: There are many ways to go about this, we recommend using seq() where from = 1, to = the length of the dataset and by = n (i.e. 3, 6 or 9). This creates an integer vector that can either used in dplyr::slice() or in row subsetting (type ?slice() or ?\"[.data.frame\" to get help on either of these methods).\nYou should now have 4 datasets with different number of rows:\n\nnrow(caro)\n## [1] 200\nnrow(caro_3)\n## [1] 67\nnrow(caro_6)\n## [1] 34\nnrow(caro_9)\n## [1] 23\n\nNow calculate timelag, steplength and speed for these data sets, just as you did in the last task. To finish the task, compare the speeds visually in a line plot and also visualize the trajectories in a map (see examples below). Interpret the line plot, what do the different lines for the different temporal granularities tell you?\nAfter completing the task, commit your changes to git using a good commit message.\n\n\n# A tibble: 67 × 6\n   TierID TierName CollarID DatetimeUTC                E        N\n   &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt; &lt;dttm&gt;                 &lt;dbl&gt;    &lt;dbl&gt;\n 1 010C   Caro        13973 2015-09-15 08:07:00 2570589. 1205095.\n 2 010C   Caro        13973 2015-09-15 08:10:00 2570518. 1205115.\n 3 010C   Caro        13973 2015-09-15 08:13:00 2570482. 1205124.\n 4 010C   Caro        13973 2015-09-15 08:16:00 2570490. 1205100.\n 5 010C   Caro        13973 2015-09-15 08:19:00 2570497. 1205092.\n 6 010C   Caro        13973 2015-09-15 08:22:00 2570499. 1205091.\n 7 010C   Caro        13973 2015-09-15 08:25:00 2570500. 1205087.\n 8 010C   Caro        13973 2015-09-15 08:28:00 2570496. 1205094.\n 9 010C   Caro        13973 2015-09-15 08:31:00 2570497. 1205091.\n10 010C   Caro        13973 2015-09-15 08:34:00 2570499. 1205091.\n# ℹ 57 more rows\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask 5 (optional): Deriving movement parameters II: Rolling window functions\nA different approach would be to smoothen the derived parameters using a moving window function. The zoo package offers a variate of moving window functions (roll_*). Install this package, load it into the session and use the function roll_mean() to smooth the calculated speed. Familiarise yourself with this function by working on some dummy data, for example:\n\nlibrary(\"zoo\")\n\nexample &lt;- rnorm(10)\nrollmean(example, k = 3, fill = NA, align = \"left\")\n\n [1]  0.08535123  0.03167662  0.32703780  0.75301689  0.38239943 -0.49261482\n [7] -0.72417943 -0.58136316          NA          NA\n\nrollmean(example, k = 4, fill = NA, align = \"left\")\n\n [1]  0.2545332  0.1979736  0.4453050  0.4773194 -0.1952450 -0.3431079\n [7] -0.5234657         NA         NA         NA\n\n\nNow run rollmeanon the speed variable of the subset (caro). Visualize the output from your moving windows and compare different window sizes (k =). After completing the task, commit your changes to git using a good commit message. Additionally, push all your commits to your remote repository on Github by clicking the green upwards pointing arrow in the Git pane in RStudio.\n\n\nTask 6: Add your movement data to your repository\nIn the semester project, you will analyse your own movement data, either collected with the Posmo App or with the GPS Tracker (see Preparation Project). Acquire this data and save it to a subfolder of your current R Project named data. To acquire it, proceed as follows:\n\nPosmo App Users\n\nGo to posmo.datamap.io and choose “Posmo Project”\nClick on the download button in the top right corner\nChoose an appropriate start and end date for which you want to download the data. Since you want all the data, you can choose 1. January until today\nClick on download\nMove the file from your downloads folder to the subfolder data in your current RStudio Project\n\nGPS Logger Users: Bring us your logger, we will extract your data and send it to you.\n\n\n\n\n\n\n\nImportant\n\n\n\nDO NOT COMMIT ANYTHING YET. Since your movement data is sensitive, personal information, we do not recommend pushing it to a public GitHub repo.\nFirst, check if Git recognized your added file by having a look at the Git Pane in RStudio. Do you see your file there? If you do, good. If you don’t, get in touch with us.\nNow, to prevent Git from publishing your data to GitHub, create a new text file in RStudio (click on File → New File → Text File). In this file, add the name of your data-folder (e.g. data/), then save the file with the name .gitignore in your project folder. Git will ignore all files and folders listed in this file.\nTo make sure it worked, check the Git Pane of Rstudio. Do you see your movement data listed here? If not, it worked! If you still see it there, get in touch wih us.\n\n\n\n\nTask 7: Explore your movement data\nNow, import your data in the same way you imported the the wild boar data in task 1. Next, start exploring your data, similarly as you did in task 2. At a minimum:\n\nImport your data as a data frame and convert it to an sf object, using the correct CRS information\nConvert your data to CH1903+ LV95\nMake a map of your data using ggplot2 or tmap.\n\n\n\nSubmission\nTo submit your exercise, provide us with the URL of your Github repo as described in the preperation.\nYou can give other GitHub users write access to your repository throught the repository settings. You will be needing this for your semester project. To practice this, add Dominik (@DLND8) and Nils (@ratnanil) to your GitHub repo:\n\nGo to your GitHub repository on GitHub.com\nGo to the repository settings by clicking on the Settings tab\nIn the left panel, click on Collaborators and teams and then Add people\nAdd the mentioned Persons via their GitHub Usernames, give them Write privilages.\n\n\n\n\n\nLaube, Patrick, and Ross S. Purves. 2011. “How Fast Is a Cow? Cross - Scale Analysis of Movement Data.” Transactions in GIS 15 (3): 401–18. https://doi.org/10.1111/j.1467-9671.2011.01256.x.",
    "crumbs": [
      "Exercise 2",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Tasks and Inputs</span>"
    ]
  },
  {
    "objectID": "Week2/W2_6_solutions.html",
    "href": "Week2/W2_6_solutions.html",
    "title": "Solutions",
    "section": "",
    "text": "Tip\n\n\n\nHover over the code and copy the content by clicking on the clipboard icon on the top right. You can now paste this into an R-Script.\n\n\n\n\n# task_1.R\n################################################################################\n\n\nlibrary(\"readr\") \nlibrary(\"sf\") \n\nwildschwein_BE &lt;- read_delim(\"datasets/wildschwein_BE_2056.csv\", \",\")\n\nwildschwein_BE &lt;- st_as_sf(wildschwein_BE, coords = c(\"E\", \"N\"), crs = 2056, remove = FALSE)\n\n\n\n\n# task_2.R\n################################################################################\n\n\nlibrary(\"dplyr\") \n\nlibrary(\"lubridate\") \nlibrary(\"ggplot2\") \n\nwildschwein_BE &lt;- wildschwein_BE |&gt;\n  mutate(timelag = as.numeric(difftime(lead(DatetimeUTC), DatetimeUTC, units = \"secs\")))\n\nggplot(wildschwein_BE, aes(DatetimeUTC, TierID)) +\n  geom_line()\n\nggplot(wildschwein_BE, aes(timelag)) +\n  geom_histogram(binwidth = 50) +\n  lims(x = c(0, 15000)) +\n  scale_y_log10()\n\n\nwildschwein_BE |&gt;\n  filter(year(DatetimeUTC) == 2014) |&gt;\n  ggplot(aes(DatetimeUTC, timelag, colour = TierID)) +\n  geom_line() +\n  geom_point()\n\n\n\n\n# task_3.R\n################################################################################\n\n\nwildschwein_BE &lt;- wildschwein_BE |&gt;\n  group_by(TierID) |&gt;\n  mutate(\n    steplength = sqrt((E-lead(E))^2+(N-lead(N))^2)\n  )\n\nwildschwein_BE &lt;- wildschwein_BE |&gt;\n  group_by(TierID) |&gt;\n  mutate(\n    speed = steplength/timelag\n  )\n\n\n\n\n# task_4.R\n################################################################################\n\n\ncaro &lt;- read_delim(\"datasets/caro60.csv\", \",\")\n\ncaro[seq(1, nrow(caro), 3), ]\n\ncaro_3 &lt;- caro[seq(1, nrow(caro), 3), ]\n\ncaro_6 &lt;- caro[seq(1, nrow(caro), 6), ]\n\ncaro_9 &lt;- caro[seq(1, nrow(caro), 9), ]\n\ncaro &lt;- caro |&gt;\n  mutate(\n    timelag = as.numeric(difftime(lead(DatetimeUTC), DatetimeUTC, units = \"secs\")),\n    steplength = sqrt((E - lead(E))^2 + (N - lead(N))^2),\n    speed = steplength / timelag\n  )\n\ncaro_3 &lt;- caro_3 |&gt;\n  mutate(\n    timelag = as.numeric(difftime(lead(DatetimeUTC), DatetimeUTC, units = \"secs\")),\n    steplength = sqrt((E - lead(E))^2 + (N - lead(N))^2),\n    speed = steplength / timelag\n  )\n\ncaro_6 &lt;- caro_6 |&gt;\n  mutate(\n    timelag = as.numeric(difftime(lead(DatetimeUTC), DatetimeUTC, units = \"secs\")),\n    steplength = sqrt((E - lead(E))^2 + (N - lead(N))^2),\n    speed = steplength / timelag\n  )\n\ncaro_9 &lt;- caro_9 |&gt;\n  mutate(\n    timelag = as.numeric(difftime(lead(DatetimeUTC), DatetimeUTC, units = \"secs\")),\n    steplength = sqrt((E - lead(E))^2 + (N - lead(N))^2),\n    speed = steplength / timelag\n  )\n\nggplot() +\n  geom_point(data = caro, aes(E, N, colour = \"1 minute\"), alpha = 0.2) +\n  geom_path(data = caro, aes(E, N, colour = \"1 minute\"), alpha = 0.2) +\n  geom_point(data = caro_3, aes(E, N, colour = \"3 minutes\")) +\n  geom_path(data = caro_3, aes(E, N, colour = \"3 minutes\")) +\n  labs(color = \"Trajectory\", title = \"Comparing original- with 3 minutes-resampled data\") +\n  theme_minimal()\n\nggplot() +\n  geom_point(data = caro, aes(E, N, colour = \"1 minute\"), alpha = 0.2) +\n  geom_path(data = caro, aes(E, N, colour = \"1 minute\"), alpha = 0.2) +\n  geom_point(data = caro_6, aes(E, N, colour = \"6 minutes\")) +\n  geom_path(data = caro_6, aes(E, N, colour = \"6 minutes\")) +\n  labs(color = \"Trajectory\", title = \"Comparing original- with 6 minutes-resampled data\") +\n  theme_minimal()\n\nggplot() +\n  geom_point(data = caro, aes(E, N, colour = \"1 minute\"), alpha = 0.2) +\n  geom_path(data = caro, aes(E, N, colour = \"1 minute\"), alpha = 0.2) +\n  geom_point(data = caro_9, aes(E, N, colour = \"9 minutes\")) +\n  geom_path(data = caro_9, aes(E, N, colour = \"9 minutes\")) +\n  labs(color = \"Trajectory\", title = \"Comparing original- with 9 minutes-resampled data\") +\n  theme_minimal()\n\nggplot() +\n  geom_line(data = caro, aes(DatetimeUTC, speed, colour = \"1 minute\")) +\n  geom_line(data = caro_3, aes(DatetimeUTC, speed, colour = \"3 minutes\")) +\n  geom_line(data = caro_6, aes(DatetimeUTC, speed, colour = \"6 minutes\")) +\n  geom_line(data = caro_9, aes(DatetimeUTC, speed, colour = \"9 minutes\")) +\n  labs(x = \"Time\", y = \"Speed (m/s)\", title = \"Comparing derived speed at different sampling intervals\") +\n  theme_minimal()\n\n\n\n\n# task_5.R\n################################################################################\n\n\n  library(\"zoo\")\n\nexample &lt;- rnorm(10)\nrollmean(example, k = 3, fill = NA, align = \"left\")\nrollmean(example, k = 4, fill = NA, align = \"left\")\n\ncaro &lt;- caro |&gt;\n  mutate(\n    speed3 = rollmean(speed, 3, NA, align = \"left\"),\n    speed6 = rollmean(speed, 6, NA, align = \"left\"),\n    speed9 = rollmean(speed, 9, NA, align = \"left\")\n  )\n\ncaro |&gt;\n  ggplot() +\n  geom_line(aes(DatetimeUTC, speed), colour = \"#E41A1C\") +\n  geom_line(aes(DatetimeUTC, speed3), colour = \"#377EB8\") +\n  geom_line(aes(DatetimeUTC, speed6), colour = \"#4DAF4A\") +\n  geom_line(aes(DatetimeUTC, speed9), colour = \"#984EA3\")",
    "crumbs": [
      "Exercise 2",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Solutions</span>"
    ]
  },
  {
    "objectID": "Week3/W3_3_preparation.html",
    "href": "Week3/W3_3_preparation.html",
    "title": "Preparation",
    "section": "",
    "text": "We need to create a new RStudio Project with Git and Github this week. Last week you created an RStudio Project which was automatically connected to Github. You did this by first creating a Github Repo, and then initiating the RStudio Project via File &gt; New Project &gt; Version Control &gt; Git (adding the URL of your Github Repo). This is definitely the easiest way to set up a connection, but what if you have an existing project that you want to connect to Github?\nIn this next section, we will go through setting up Git and Github without the use of RStudio. It will take slightly longer than the setup we used last week. Also, you will be confronted with some additional jargon.\nAs additional ressources to learning Git, we highly recommend:\n\nThe video tutorials by Corey Schafer or the very entertaining learning series Git and Github for Poets.\nHappy Git with Github for the useR is an excellent, easy to read, openly available book, written specifically for students working with R and RStudio in data science and related fields\n\n\nStep 1: Create a “normal” RStudio Project\nCreate a new RStudio Project File &gt; New Project &gt; New Directory &gt; New Project. This will create a “normal” RStudio Project without Git version control (and consequently without a Github connection). This is a typical situation for a project that you started without version control in mind. Choose the following settings:\n\nDirectory name: Choose a directory name that suits your structure\nCreate project as a subdirectory of: Choose a parent directory that suits your folder structure\nCreate a git repository: not checked (we will do this manually in the next step)\nUse renv with this project: not checked\n\n\n\nStep 2: Activate Git Version Control\nActivating Git Version Control for your project is one line of code. In your shell terminal, type the following command (which is what RStudio effectively does automatically when you activate the Create a git repository option while creating your project):\ngit init\nYou should get a message, saying Initialized empty Git repository in C:/path/to/your/directory/.git/. You will see this folder (named .git) in your project’s root directory (check your “Files” pane ). If you don’t see it there, click Refresh file listing (refresh symbol to the very right of the files pane). If you still don’t see it, make hidden files visible (Files pane &gt; More &gt; Show hidden files)\nTo see the “Git” Pane in RStudio, reload RStudio either by restarting it or clicking on the name of your RStudio project in the top right corner of RStudio and selecting your project from the project list).\n\n\nStep 3: Create a Github Repository\nNow create a Github Repository following the instructions from last week. This time however, don’t check Add a README file.\nCopy the https URL to your Github repo, which should look something like this: https://github.com/YOUR-GITHUB-USERNAME/cma-week3.git\n\n\n\n\n\n\nImportant\n\n\n\nReport the URL of your new repo back to us via Moodle!\n\n\n\n\nStep 4: Connect to Github\nTo connect your (local) RStudio Project to Github, we have to set up our Github repo to be our so called “remote” repository. We could have multiple remotes, which is why we need to name it, and the convention is to call it origin. To create a remote named origin, type the following command in your shell terminal:\ngit remote add origin https://github.com/YOUR-GITHUB-USERNAME/cma-week3.git\nNow, before you can push anything to the remote repository, you need to commit something first. Last week, you used the Git Pane from RStudio to commit your files. Since we are already in the terminal, let’s use the terminal for this and in this way get to know git a little bit better.\nThere is one little that we glanced over till now. Before committing a file, you selected them first. This process is called adding to the staging area. To add your cma-week3.rproj to your git repo, type the following command:\n# Adjust the filename accordingly\ngit add cma-week3.rproj\nTo commit this file, type the following command\n# The text after -m is your commit message\ngit commit -m \"my initial commit\"\nThe first time we push to this remote repository, we need to specify the an upstream, so that future git push will be directed to the correct remote branch. We can to this with the --set-upstream (or -u)\nAssuming your branch is called main, type the following command. You can check the name of your branch with command git branch (the default branch name is either main or master).\ngit push --set-upstream origin main\nThis command prints a couple of messages, ending with the following statement: Branch 'main' set up to track remote branch 'main' from 'origin'.. Now that the upstream (i.e.) tracking branch is correctly set up, you can also push via the Git pane in RStudio (you might need to refresh the Git pane first).",
    "crumbs": [
      "Exercise 3",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Preparation</span>"
    ]
  },
  {
    "objectID": "Week3/W3_4_tasks_and_inputs.html",
    "href": "Week3/W3_4_tasks_and_inputs.html",
    "title": "Tasks and Inputs",
    "section": "",
    "text": "You’ve read Laube and Purves (2011) about segmenting trajectories. In the paper, the authors define “static” fixes as “those whose average Euclidean distance to other fixes inside a temporal window v is less than some threshold d”, as illustrated in the following figure:\n\n\n\n\n\n\nFigure 11.1: The figure from Laube and Purves (2011) visualizes steps a) zu d), which will be explained below\n\n\n\n\nSpecify a temporal windows \\(v\\) for in which to measure Euclidean distances\nMeasure the distance from every point to every other point within this temporal window \\(v\\)\nRemove “static points”: These are points where the average distance is less than a given threshold. This segments the trajectory into subtrajectories\nNow remove short subtrajectories: These are trajectories with a short duration (whereas “short” is tbd)\n\nWe will demonstrate implementing this method on the wild boar “Sabi”, restricting ourselves to a couple of tracking days. Your task will be to understand this implementation and apply it to your own movement data.\nOpen the RStudio Project you have prepared for this week. Next, copy the wildboar data you downloaded last week (wildschwein_BE_2056.csv) to your project folder. If you cannot find this dataset on your computer, you can re-download it here\n\n\nCode\nlibrary(\"readr\")\nlibrary(\"dplyr\")\n\nwildschwein &lt;- read_delim(\"datasets/wildschwein_BE_2056.csv\", \",\")\n\nsabi &lt;- wildschwein |&gt;\n    filter(TierName == \"Sabi\", DatetimeUTC &gt;= \"2015-07-01\", DatetimeUTC &lt; \"2015-07-03\")\n\n\n\n\n\n\n\nMovement of the wildboar ‘Sabi’ in the timespan 01 - 02.07.2015. The circle highlingts possible ‘static points’\n\n\n\n\n\nStep a): Specify a temporal window \\(v\\)\nIn the above dataset, the sampling interval is 15 minutes. If we take a temporal window of 60 minutes, that would mean including 4 fixes. We need to calculate the following Euclidean distances (pos representing single location):\n\npos[n-2] to pos[n]\npos[n-1] to pos[n]\npos[n] to pos[n+1]\npos[n] to pos[n+2]\n\n\n\nStep b): Measure the distance from every point to every other point within this temporal window \\(v\\)\nJust like last week, we use the formula for calculating the Euclidean distance in in combination with lead() and lag(). For example, to create the necessary offset of n-2, we use lag(x, 2). For each offset, we create one individual column.\n\nsabi &lt;- sabi |&gt;\n    mutate(\n        nMinus2 = sqrt((lag(E, 2) - E)^2 + (lag(N, 2) - N)^2), # distance to pos -30 minutes\n        nMinus1 = sqrt((lag(E, 1) - E)^2 + (lag(N, 1) - N)^2), # distance to pos -15 minutes\n        nPlus1  = sqrt((E - lead(E, 1))^2 + (N - lead(N, 1))^2), # distance to pos +15 mintues\n        nPlus2  = sqrt((E - lead(E, 2))^2 + (N - lead(N, 2))^2) # distance to pos +30 minutes\n    )\n\nNow we want to calculate the mean distance of nMinus2, nMinus1, nPlus1, nPlus2 for each row. Since we want the mean value per Row, we have to explicitly specify this before mutate() with the function rowwise(). To remove this rowwise-grouping, we end the operation with ungroup().\nNote that for the first two positions, we cannot calculate a stepMean since there is no Position n-2 for these positions. This is also true for the last to positions (lacking a position n+2).\n\nsabi &lt;- sabi |&gt;\n    rowwise() |&gt;\n    mutate(\n        stepMean = mean(c(nMinus2, nMinus1, nPlus1, nPlus2))\n    ) |&gt;\n    ungroup()\n\nsabi\n\n# A tibble: 192 × 11\n   TierID TierName CollarID DatetimeUTC                E       N nMinus2 nMinus1\n   &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt; &lt;dttm&gt;                 &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 002A   Sabi        12275 2015-07-01 00:00:10 2570532.  1.21e6    NA      NA  \n 2 002A   Sabi        12275 2015-07-01 00:15:14 2570530.  1.21e6    NA      15.4\n 3 002A   Sabi        12275 2015-07-01 00:30:11 2570676.  1.21e6   159.    155. \n 4 002A   Sabi        12275 2015-07-01 00:45:43 2570707.  1.21e6   177.     63.1\n 5 002A   Sabi        12275 2015-07-01 01:00:20 2570656.  1.21e6    22.0    68.3\n 6 002A   Sabi        12275 2015-07-01 01:15:59 2570850.  1.21e6   144.    204. \n 7 002A   Sabi        12275 2015-07-01 01:31:02 2570819.  1.21e6   173.     31.7\n 8 002A   Sabi        12275 2015-07-01 01:45:37 2570863.  1.21e6   112.    112. \n 9 002A   Sabi        12275 2015-07-01 02:00:17 2570863.  1.21e6   137.     27.1\n10 002A   Sabi        12275 2015-07-01 02:15:13 2570891.  1.21e6    35.5    29.2\n# … with 182 more rows, and 3 more variables: nPlus1 &lt;dbl&gt;, nPlus2 &lt;dbl&gt;,\n#   stepMean &lt;dbl&gt;\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\n\nStep c): Remove “static points”\nWe can now determine if an animal is moving or not by specifying a threshold distance on stepMean. In our example, we use the mean value as a threshold: Positions with distances below this value are considered static.\n\nsabi &lt;- sabi |&gt;\n    ungroup() |&gt;\n    mutate(static = stepMean &lt; mean(stepMean, na.rm = TRUE))\n\nsabi_filter &lt;- sabi |&gt;\n    filter(!static)\n\nsabi_filter |&gt;\n    ggplot(aes(E, N)) +\n    geom_path() +\n    geom_point() +\n    coord_fixed() +\n    theme(legend.position = \"bottom\")\n\n\n\n\nThe trajectory of sabi, filtered to the positions where the animal was not static\n\n\n\n\n\n\nPreperation\nWith the skills from the input above you can now implement the segmentation algorithm described in Laube and Purves (2011) to your own movement data. Grab your data from last week (or get the most current data from your posmo interface or tracker device) and import it as data.frame. Add this data to the .gitignore file to prevent it from being uploaded to GitHub.\n\nlibrary(\"readr\")\nlibrary(\"sf\")\n\nposmo &lt;- read_delim(\"datasets/posmo_2022-05-01T00 00 00+02 00-2023-04-18T23 59 59+02 00.csv\")\n\n# Keep only the necessary columns\nposmo &lt;- select(posmo, datetime, lon_x, lat_y)\n\nAs before, we will calculate the euclidean distance “by hand”. This means we need the coordinates of our locations stored in a Projected CRS. Our data is stored in a geodetic coordinate reference system (WGS84, i.e. EPSG 4326). We can transform the data to EPSG 2056 with the function st_transform, as we explained in the first week.\n\nposmo &lt;- st_as_sf(posmo, coords = c(\"lon_x\",\"lat_y\"), crs = 4326) |&gt;\n  st_transform(2056)\n\nhead(posmo)\n\nSimple feature collection with 6 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2694031 ymin: 1230386 xmax: 2694100 ymax: 1230406\nProjected CRS: CH1903+ / LV95\n# A tibble: 6 × 2\n  datetime                     geometry\n  &lt;dttm&gt;                    &lt;POINT [m]&gt;\n1 2022-11-29 14:42:11 (2694100 1230386)\n2 2022-11-29 16:01:14 (2694100 1230386)\n3 2022-11-29 16:01:14 (2694061 1230396)\n4 2022-11-29 16:01:23 (2694051 1230402)\n5 2022-11-29 16:01:33 (2694040 1230406)\n6 2022-11-29 16:01:42 (2694031 1230401)\n\n\nTo be able to compute euclidean distances by hand, we need the coordinates stored in separate columns. The function st_coordinates extracts the coordinates from our sf object. We can bind these coordinates back to our sf object using cbind\n\nposmo_coordinates &lt;- st_coordinates(posmo)\n\nposmo &lt;- cbind(posmo, posmo_coordinates)\n\nExplore your data and choose a single day for the next steps.\n\nposmo_filter &lt;- posmo |&gt;\n    filter(as.Date(datetime) == \"2023-03-23\")\n\nOnce you have completed the task, commit your changes with a meaningful commit message. Before committing, make sure your location data is ignored. Then, test your connection to Github by pushing your changes to your remote repository.\n\n\nTask 1: Segmentation\nNow, you can implement steps a) b) and c), which you had used with sabi, on on your own movement data. Once you have completed the task, commit your changes with a meaningful commit message and test your connection to Github by pushing your changes to your remote repository.\n\n\nTask 2: Specify and apply threshold d\nAfter calculating the Euclidean distances to positions within the temporal window v in task 1, you can explore these values (we stored them in the column stepMean) using summary statistics (histograms, boxplot, summary()): This way we can define a reasonable threshold value to differentiate between stops and moves. There is no “correct” way of doing this, specifying a threshold always depends on data as well as the question that needs to be answered. In this exercise, use the mean of all stepMean values.\nStore the new information (boolean to differentiate between stops (TRUE) and moves (FALSE)) in a new column named static.\nCommit your changes with a meaningful commit message.\n\n\nTask 3: Visualize segmented trajectories\nNow visualize the segmented trajectory spatially. Just like last week, you can use ggplot with geom_path(), geom_point() and coord_equal(). Assign colour = static within aes() to distinguish between segments with “movement” and without.\nCommit your changes with a meaningful commit message.\n\n\n\n\n\n\n\n\n\n\n\nTask 4: Segment-based analysis\nIn applying Laube and Purves (2011), we’ve come as far as step b) in Figure 11.1. In order to complete the last steps (c and d), we need a unique ID for each segment that we can use as a grouping variable. The following function does just that (it assigns unique IDs based on the column static which you created in Task 2). You will learn about functions next week. For now, just copy the following code chunk into your script and run it.\n\nrle_id &lt;- function(vec) {\n    x &lt;- rle(vec)$lengths\n    as.factor(rep(seq_along(x), times = x))\n}\n\nYou can use the newly created function rle_id to assign unique IDs to subtrajectories (as shown below). Visualize the moving segments by colourizing them by segment_ID. Then use segment_ID as a grouping variable to determine the segments duration and remove short segments (e.g. segments with a duration &lt; 5 Minutes)\nCommit your changes with a meaningful commit message.\n\nposmo_filter &lt;- posmo_filter |&gt;\n    mutate(segment_id = rle_id(static))\n\nhead(posmo_filter)\n\nSimple feature collection with 6 features and 6 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2678783 ymin: 1232937 xmax: 2678924 ymax: 1233006\nProjected CRS: CH1903+ / LV95\n                 datetime       X       Y                geometry stepMean\n39774 2023-03-23 07:21:29 2678924 1233006 POINT (2678924 1233006)       NA\n39775 2023-03-23 07:21:29 2678924 1233006 POINT (2678924 1233006)       NA\n39776 2023-03-23 07:21:29 2678924 1233006 POINT (2678924 1233006)       NA\n39777 2023-03-23 07:21:39 2678783 1232937 POINT (2678783 1232937) 137.2258\n39778 2023-03-23 07:21:39 2678783 1232937 POINT (2678783 1232937) 141.1740\n39779 2023-03-23 07:21:39 2678783 1232937 POINT (2678783 1232937) 145.1222\n      static segment_id\n39774     NA          1\n39775     NA          2\n39776     NA          3\n39777   TRUE          4\n39778   TRUE          4\n39779   TRUE          4\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask 5: Similarity measures\nWe will now calculate similarties between trajectories using a new dataset pedestrian.csv. Download an import this dataset as a data.frame or tibble. It it a set of six different but similar trajectories from pedestrians walking on a path.\nFor this task, explore the trajectories first and get an idea on how the pedestrians moved.\nCommit your changes with a meaningful commit message.\n\n\n\n\n\n\n\n\n\n\n\nTask 6: Calculate similarity\nInstall the package SimilarityMeasures (install.packages(\"SimilarityMeasures\")). Familiarize yourself with this package by skimming through the function descriptions help(package = \"SimilarityMeasures\"). Now compare trajectory 1 to trajectories 2-6 using different similarity measures from the package. Your options are. DTW, EditDist, Frechet and LCSS.\nBefore visualizing your results think about the following: Which two trajectories to you percieve to be most similar, which are most dissimilar? Now visualize the results from the computed similarity measures. Which measure reflects your own intuition the closest?\nNote:\n\nAll functions in the package need matrices as input, with one trajectory per matrix.\nLCSStakes very long to compute. The accuracy of the algorithm (pointSpacing = ,pointDistance = and errorMarg =) can be varied to provide faster calculations. Please see Vlachos, Gunopoulos, and Kollios (2002) for more information.\n\nCommit your changes with a meaningful commit message. Now push all your changes to Github.\n\n\n\n\n\n\n\n\n\n\n\nSubmission\nTo submit your exercise, provide us with the URL of your Github repo as described in the preperation.\n\n\n\n\nLaube, Patrick, and Ross S. Purves. 2011. “How Fast Is a Cow? Cross - Scale Analysis of Movement Data.” Transactions in GIS 15 (3): 401–18. https://doi.org/10.1111/j.1467-9671.2011.01256.x.\n\n\nVlachos, Michail, Dimitrios Gunopoulos, and George Kollios. 2002. “Discovering Similar Multidimensional Trajectories.” In Proceedings of the 18th International Conference on Data Engineering, 673–73. ICDE ’02. Washington, DC, USA: IEEE Computer Society. http://dl.acm.org/citation.cfm?id=876875.878994.",
    "crumbs": [
      "Exercise 3",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Tasks and Inputs</span>"
    ]
  },
  {
    "objectID": "Week3/W3_5_solutions.html",
    "href": "Week3/W3_5_solutions.html",
    "title": "Solutions",
    "section": "",
    "text": "Tip\n\n\n\nHover over the code and copy the content by clicking on the clipboard icon on the top right. You can now paste this into an R-Script.\n\n\n\n\n# task 1 ########################################################################\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\ncaro60 &lt;- read_delim(\"datasets/caro60.csv\", \",\")\n\ncaro60 &lt;- caro60 %&gt;%\n  mutate(\n    stepMean = rowMeans(\n      cbind(\n        sqrt((lag(E, 3) - E)^2 + (lag(E, 3) - E)^2),\n        sqrt((lag(E, 2) - E)^2 + (lag(E, 2) - E)^2),\n        sqrt((lag(E, 1) - E)^2 + (lag(E, 1) - E)^2),\n        sqrt((E - lead(E, 1))^2 + (E - lead(E, 1))^2),\n        sqrt((E - lead(E, 2))^2 + (E - lead(E, 2))^2),\n        sqrt((E - lead(E, 3))^2 + (E - lead(E, 3))^2)\n      )\n    )\n  )\n\n# Note:\n# We present here a slightly different approach as presented in the input:\n# - cbind() creates a matrix with the same number of rows as the original dataframe\n# - It has 6 columns, one for each Euclidean distance calculation\n# - rowMeans() returns a single vector with the same number of rows as the original dataframe\n\n\n# task 2 ########################################################################\n\nsummary(caro60$stepMean)\n\nggplot(caro60, aes(stepMean)) +\n  geom_histogram(binwidth = 1) +\n  geom_vline(xintercept = mean(caro60$stepMean, na.rm = TRUE))\n\ncaro60 &lt;- caro60 %&gt;%\n  mutate(\n    static = stepMean &lt; mean(caro60$stepMean, na.rm = TRUE)\n  )\n\n\n# task 3 ########################################################################\n\ncaro60 %&gt;%\n  ggplot() +\n  geom_path(aes(E, N), alpha = 0.5) +\n  geom_point(aes(E, N, colour = static)) +\n  theme_minimal() +\n  coord_equal()\n\n\n# task 4 ########################################################################\n\ncaro60 &lt;- caro60 %&gt;%\n  mutate(\n    segment_ID = rle_id(static)\n  )\n\ncaro60_moves &lt;- caro60 %&gt;%\n  filter(!static)\n\np1 &lt;- ggplot(caro60_moves, aes(E, N, color = segment_ID)) +\n  geom_point() +\n  geom_path() +\n  coord_equal() +\n  theme(legend.position = \"none\") +\n  labs(subtitle = \"All segments (uncleaned)\")\n\np2 &lt;- caro60_moves %&gt;%\n  group_by(segment_ID) %&gt;%\n  mutate(duration = as.integer(difftime(max(DatetimeUTC), min(DatetimeUTC), \"mins\"))) %&gt;%\n  filter(duration &gt; 5) %&gt;%\n  ggplot(aes(E, N, color = segment_ID)) +\n  # geom_point(data = caro60, color = \"black\") +\n  geom_point() +\n  geom_path() +\n  coord_equal() +\n  theme(legend.position = \"none\") +\n  labs(subtitle = \"Long segments (removed segements &lt;5 minutes)\")\n\n\n# task 5 ########################################################################\n\npedestrians &lt;- read_delim(\"datasets/pedestrian.csv\", \",\")\n\nggplot(pedestrians, aes(E, N)) +\n  geom_point(data = dplyr::select(pedestrians, -TrajID), alpha = 0.1) +\n  geom_point(aes(color = as.factor(TrajID)), size = 2) +\n  geom_path(aes(color = as.factor(TrajID))) +\n  facet_wrap(~TrajID, labeller = label_both) +\n  coord_equal() +\n  theme_minimal() +\n  labs(title = \"Visual comparison of the 6 trajectories\", subtitle = \"Each subplot highlights a trajectory\") +\n  theme(legend.position = \"none\")\n\n\n# task 6 ########################################################################\n\nlibrary(SimilarityMeasures) # for the similarity measure functions\n\n# all functions compare two trajectories (traj1 and traj2). Each trajectory\n# must be an numeric matrix of n dimensions. Since our dataset is spatiotemporal\n# we need to turn our Datetime column from POSIXct to integer:\n\npedestrians &lt;- pedestrians %&gt;%\n  mutate(Datetime_int = as.integer(DatetimeUTC))\n\n# Next, we make an object for each trajectory only containing the\n# coordinates in the three-dimensional space and turn it into a matrix\n\ntraj1 &lt;- pedestrians %&gt;%\n  filter(TrajID == 1) %&gt;%\n  dplyr::select(E, N, Datetime_int) %&gt;%\n  as.matrix()\n\n# But instead of repeating these lines 6 times, we turn them into a function.\n# (this is still more repetition than necessary, use the purr::map if you know\n# how!)\n\ndf_to_traj &lt;- function(df, traj) {\n  df %&gt;%\n    filter(TrajID == traj) %&gt;%\n    dplyr::select(E, N, Datetime_int) %&gt;%\n    as.matrix()\n}\n\ntraj2 &lt;- df_to_traj(pedestrians, 2)\ntraj3 &lt;- df_to_traj(pedestrians, 3)\ntraj4 &lt;- df_to_traj(pedestrians, 4)\ntraj5 &lt;- df_to_traj(pedestrians, 5)\ntraj6 &lt;- df_to_traj(pedestrians, 6)\n\n# Then we can start comparing trajectories with each other\n\ndtw_1_2 &lt;- DTW(traj1, traj2)\ndtw_1_3 &lt;- DTW(traj1, traj3)\n\n# ... and so on. Since this also leads to much code repetition, we will\n# demostrate a diffferent approach:\n\n# Instead of creating 6 objects, we can also create a single list containing 6\n# elements by using \"split\" and \"purrr::map\"\n\nlibrary(purrr)\n\npedestrians_list &lt;- map(1:6, function(x) {\n  df_to_traj(pedestrians, x)\n})\n\ncomparison_df &lt;- map_dfr(2:6, function(x) {\n  tibble(\n    trajID = x,\n    DTW = DTW(pedestrians_list[[1]], pedestrians_list[[x]]),\n    EditDist = EditDist(pedestrians_list[[1]], pedestrians_list[[x]]),\n    Frechet = Frechet(pedestrians_list[[1]], pedestrians_list[[x]]),\n    LCSS = LCSS(pedestrians_list[[1]], pedestrians_list[[x]], 5, 4, 4)\n  )\n})\n\nlibrary(tidyr) # for pivot_longer\n\ncomparison_df %&gt;%\n  pivot_longer(-trajID) %&gt;%\n  ggplot(aes(trajID, value, fill = as.factor(trajID))) +\n  geom_bar(stat = \"identity\") +\n  facet_wrap(~name, scales = \"free\") +\n  theme(legend.position = \"none\") +\n  labs(x = \"Comparison trajectory\", y = \"Value\", title = \"Computed similarities using different measures \\nbetween trajectory 1 to all other trajectories \")",
    "crumbs": [
      "Exercise 3",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Solutions</span>"
    ]
  },
  {
    "objectID": "Week4/W4_3_preparation.html",
    "href": "Week4/W4_3_preparation.html",
    "title": "Preparation",
    "section": "",
    "text": "Create a new RStudio Project and a new Github Repo for this week’s exercises. Do this either the simple way we used in Exercise 2 (Step 3 and then Step 4) or the more sophisticated way we suggested in Exercise 3.\nIf you want to publish your Report as a website (to share with others), activate Github Pages by going to your repo on Github, clicking on Settings &gt; Pages, and under Source switch from None to your Main branch. You can do this only after pushing your first commit.",
    "crumbs": [
      "Exercise 4",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Preparation</span>"
    ]
  },
  {
    "objectID": "Week4/W4_4_tasks_and_inputs.html",
    "href": "Week4/W4_4_tasks_and_inputs.html",
    "title": "Tasks and inputs",
    "section": "",
    "text": "Task 1: Write your own functions\nCreate a function for our Euclidean distance calculation.\nNote: if you treat your input variables as vectors, they will work in dplyrs mutate() and summarise() operations.",
    "crumbs": [
      "Exercise 4",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Tasks and inputs</span>"
    ]
  },
  {
    "objectID": "Week4/W4_4_tasks_and_inputs.html#footnotes",
    "href": "Week4/W4_4_tasks_and_inputs.html#footnotes",
    "title": "Tasks and inputs",
    "section": "",
    "text": "Please note: We are manipulating our time stamps without adjusting the x,y-coordinates. This is fine for our simple example, but we would advice against this in a more serious research endeavour, e.g. in your semester projects. One simple approach would be to linearly interpolate the positions to the new timestamps. If you choose Option A the wild boar projects as your semester projects, you should aim for a linear interpolation. Get in touch if you need help with this.↩︎",
    "crumbs": [
      "Exercise 4",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Tasks and inputs</span>"
    ]
  },
  {
    "objectID": "Week4/W4_6_solutions.html",
    "href": "Week4/W4_6_solutions.html",
    "title": "Solutions",
    "section": "",
    "text": "Tip\n\n\n\nHover over the code and copy the content by clicking on the clipboard icon on the top right. You can now paste this into an R-Script.\n\n\n\n\n# task 1 ########################################################################\n\neuclid &lt;- function(x, y, leadval = 1) {\n  sqrt((x - lead(x, leadval))^2 + (y - lead(y, leadval))^2)\n}\n\n\n# task 2 ########################################################################\n\nwildschwein &lt;- read_delim(\"datasets/wildschwein_BE_2056.csv\", \",\")\n\nwildschwein_filter &lt;- wildschwein %&gt;%\n       filter(\n              DatetimeUTC &gt; \"2015-04-01\",\n              DatetimeUTC &lt; \"2015-04-15\"\n       ) %&gt;%\n       filter(TierName %in% c(\"Rosa\", \"Sabi\"))\n\n\n# task 3 ########################################################################\n\nwildschwein_filter &lt;- wildschwein_filter %&gt;%\n  group_by(TierID) %&gt;%\n  mutate(\n    DatetimeRound = lubridate::round_date(DatetimeUTC, \"15 minutes\")\n  )\n\nhead(wildschwein_filter)\n\n\n# task 4 ########################################################################\n\nlibrary(purrr)\n\nsabi &lt;- wildschwein_filter %&gt;%\n  filter(TierName == \"Sabi\")\n\nrosa &lt;- wildschwein_filter %&gt;%\n  filter(TierName == \"Rosa\")\n\nwildschwein_join &lt;- full_join(sabi, rosa, by = c(\"DatetimeRound\"), suffix = c(\"_sabi\", \"_rosa\"))\n\nwildschwein_join &lt;- wildschwein_join %&gt;%\n  mutate(\n    distance = sqrt((E_rosa - E_sabi)^2 + (N_rosa - N_sabi)^2),\n    meet = distance &lt; 100\n  )\n\n\n# task 5 ########################################################################\n\nwildschwein_meet &lt;- wildschwein_join %&gt;%\n  filter(meet)\n\nggplot(wildschwein_meet) +\n  geom_point(data = sabi, aes(E, N, colour = \"sabi\"), shape = 16, alpha = 0.3) +\n  geom_point(data = rosa, aes(E, N, colour = \"rosa\"), shape = 16, alpha = 0.3) +\n  geom_point(aes(x = E_sabi, y = N_sabi, fill = \"sabi\"), shape = 21) +\n  geom_point(aes(E_rosa, N_rosa, fill = \"rosa\"), shape = 21) +\n  labs(color = \"Regular Locations\", fill = \"Meets\") +\n  coord_equal(xlim = c(2570000, 2571000), y = c(1204500, 1205500))\n\n\n# task 6 ########################################################################\n\nmeanmeetpoints &lt;- wildschwein_join %&gt;%\n  filter(meet) %&gt;%\n  mutate(\n    E.mean = (E_rosa + E_sabi) / 2,\n    N.mean = (N_rosa + N_sabi) / 2\n  )\n\nlibrary(plotly)\nplot_ly(wildschwein_join, x = ~E_rosa, y = ~N_rosa, z = ~DatetimeRound, type = \"scatter3d\", mode = \"lines\") %&gt;%\n  add_trace(wildschwein_join, x = ~E_sabi, y = ~N_sabi, z = ~DatetimeRound) %&gt;%\n  add_markers(data = meanmeetpoints, x = ~E.mean, y = ~N.mean, z = ~DatetimeRound) %&gt;%\n  layout(scene = list(\n    xaxis = list(title = \"E\"),\n    yaxis = list(title = \"N\"),\n    zaxis = list(title = \"Time\")\n  ))\n\n\nwildschwein_join %&gt;%\n  filter(DatetimeRound &lt; \"2015-04-04\") %&gt;%\n  plot_ly(x = ~E_rosa, y = ~N_rosa, z = ~DatetimeRound, type = \"scatter3d\", mode = \"lines\") %&gt;%\n  add_trace(wildschwein_join, x = ~E_sabi, y = ~N_sabi, z = ~DatetimeRound) %&gt;%\n  add_markers(data = meanmeetpoints, x = ~E.mean, y = ~N.mean, z = ~DatetimeRound) %&gt;%\n  layout(scene = list(\n    xaxis = list(title = \"E\"),\n    yaxis = list(title = \"N\"),\n    zaxis = list(title = \"Time\")\n  ))",
    "crumbs": [
      "Exercise 4",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Solutions</span>"
    ]
  },
  {
    "objectID": "Week5/W5_2_preparation.html",
    "href": "Week5/W5_2_preparation.html",
    "title": "Preparation",
    "section": "",
    "text": "Create a new RStudio Project and a new Github Repo for this week’s exercises. Do this either the simple way we used in Exercise 2 (Step 3 and then Step 4) or the more sophisticated way we suggested in Exercise 3.\nIf you want to publish your Report as a website (to share with others), activate Github Pages by going to your repo on Github, clicking on Settings &gt; Pages, and under Source switch from None to your Main branch. You can do this only after pushing your first commit.",
    "crumbs": [
      "Exercise 5",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Preparation</span>"
    ]
  },
  {
    "objectID": "Week5/W5_3_tasks_and_inputs.html",
    "href": "Week5/W5_3_tasks_and_inputs.html",
    "title": "Tasks and Inputs",
    "section": "",
    "text": "Open your RStudio Project which you prepared from this week. Create a new RScript and import the libraries we need for this week. Import your wildboar dataset wildschwein_BE_2056.csv as an sf object\n\nlibrary(\"readr\")\nlibrary(\"sf\")\nlibrary(\"terra\")\nlibrary(\"dplyr\")\nlibrary(\"lubridate\")\nlibrary(\"ggplot2\")\nlibrary(\"tmap\")\n\nwildschwein_BE &lt;- read_delim(\"datasets/wildschwein_BE_2056.csv\", \",\") |&gt;\n    st_as_sf(coords = c(\"E\", \"N\"), crs = 2056, remove = FALSE)\n\nDownload the dataset Feldaufnahmen_Fanel.gpkg and save it to your project folder. This is a vector dataset stored in the filetype Geopackage, which is similar to a Shapefile, with some advantages (see the website shapefile must die).\nAlso download the dataset vegetationshoehe_LFI.tif. This is a “raster” dataset stored in a Geotiff, similar to the map we imported in week 1. Also store this file in your project folder and commit these to your repo.\n\nTasks 1: Import and visualize spatial data\nSince Feldaufnahmen_Fanel.gpkg is a vector dataset, you can import it using read_sf(). Explore this dataset in R to answer the following questions:\n\nWhat information does the dataset contain?\nWhat is the geometry type of the dataset (possible types are: Point, Lines and Polygons)?\nWhat are the data types of the other columns?\nWhat is the coordinate system of the dataset?\n\n\n\nTask 2: Annotate Trajectories from vector data\nWe would like to know what crop was visited by which wild boar, and at what time. Since the crop data is most relevant in summer, filter your wildboar data to the months may to june first and save the output to a new variable. Overlay the filtered dataset with your fanel data to verify the spatial overlap.\nTo sematically annotate each wildboar location with crop information, you can use a spatial join with the function st_join(). Do this and explore your annotated dataset.\n\n\nTask 3: Explore annotated trajectories\nThink of ways you could visually explore the spatio-temporal patterns of wild boar in relation to the crops. In our example below we visualize the percentage of samples in a given crop per hour.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTask 4: Import and visualize vegetationindex (raster data)\nYou have already downloaded the dataset vegetationshoehe_LFI.tif. Import this dataset\nIn terms of raster data, we have prepared the Vegetation Height Model provided by the Swiss National Forest Inventory (NFI). This dataset contains high resolution information (1x1 Meter) on the vegetation height, which is determined from the difference between the digital surface models DSM and the digital terrain model by swisstopo (swissAlti3D). Buildings are eliminated using a combination of the ground areas of the swisstopo topographic landscape model (TLM) and spectral information from the stereo aerial photos.\nImport the dataset just like you imported the raster map in week 1 (using terra::rast()). Visualize the raster data using tmap (ggplot is very slow with raster data).\n\n\nTask 5: Annotate Trajectories from raster data\nSemantically annotate your wildboar locations with the vegetation index (similar as you did with the crop data in Task 2). Since you are annotating a vector dataset with information from a raster dataset, you cannot use st_join but need the function extract from the terra package. Read the help on the extract function to see what the function expects. The output should look something like this:\nYou can now explore the spatiotemporal patterns of this new data.",
    "crumbs": [
      "Exercise 5",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Tasks and Inputs</span>"
    ]
  },
  {
    "objectID": "90_references.html",
    "href": "90_references.html",
    "title": "References",
    "section": "",
    "text": "Bryan, Jenny, and Jim Heister. 2021. Happy Git and GitHub for the\nuseR. https://happygitwithr.com/.\n\n\nChacon, Scott, and Ben Straub. 2014. Pro Git. 2nd Edition.\nApress. https://git-scm.com/book/en/v2.\n\n\nHägerstraand, Torsten. 1970. “What about People in Regional\nScience?” Papers in Regional Science 24 (1): 7–24.\n\n\nLaube, Patrick, and Ross S. Purves. 2011. “How Fast Is a Cow?\nCross - Scale Analysis of Movement Data.” Transactions in\nGIS 15 (3): 401–18. https://doi.org/10.1111/j.1467-9671.2011.01256.x.\n\n\nRodrigues, Bruno. 2023. Building Reproducible Analytical Pipelines\nwith r. leanpub.\n\n\nVlachos, Michail, Dimitrios Gunopoulos, and George Kollios. 2002.\n“Discovering Similar Multidimensional Trajectories.” In\nProceedings of the 18th International Conference on Data\nEngineering, 673–73. ICDE ’02. Washington, DC, USA: IEEE Computer\nSociety. http://dl.acm.org/citation.cfm?id=876875.878994.\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science:\nImport, Tidy, Transform, Visualize, and Model Data. 1st ed.\nO’Reilly Media, Inc.",
    "crumbs": [
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>References</span>"
    ]
  }
]